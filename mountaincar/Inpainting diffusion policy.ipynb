{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "256f4d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "from diffusion_framework.ddpm_1d import DDPM_1d\n",
    "from diffusion_framework.nets import ErrorNet, CondErrorNet\n",
    "\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import gym\n",
    "import numpy as np\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
    "import platform\n",
    "if platform.system() == \"Linux\":\n",
    "    os.environ['PYOPENGL_PLATFORM'] = 'egl'\n",
    "\n",
    "### Select environment\n",
    "env_id = \"MountainCarContinuous-v0\"\n",
    "# Note that the algorithm is SAC\n",
    "\n",
    "gym_env = gym.make(env_id)\n",
    "max_obs_values = gym_env.observation_space.high\n",
    "min_obs_values = gym_env.observation_space.low\n",
    "\n",
    "max_act_value = gym_env.action_space.high\n",
    "min_act_value = gym_env.action_space.low\n",
    "\n",
    "bias = max_obs_values + min_obs_values\n",
    "bias = bias / 2\n",
    "scale = max_obs_values - min_obs_values\n",
    "scale = scale / 2\n",
    "\n",
    "env = make_vec_env(env_id, n_envs=1)\n",
    "#best_model = SAC.load('/home/sai-admin/advanced_ml_project/rl-baselines3-zoo/rl-trained-agents/sac/' + \n",
    "#                      env_id + '_1/' + \n",
    "#                      env_id + '.zip', env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c5592e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data\n",
    "expert_demo_path = 'expert/logs/expert_demonstrations.npy'\n",
    "\n",
    "dataset = np.load(expert_demo_path, allow_pickle=True)\n",
    "dataset = torch.tensor(dataset, dtype=torch.float32)\n",
    "\n",
    "batch_size = 128\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define models\n",
    "timesteps = 1000\n",
    "diffusion = DDPM_1d(timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e505134e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ErrorNet(\n",
       "  (time_mlp): Sequential(\n",
       "    (0): SinusoidalPositionEmbeddings()\n",
       "    (1): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (2): GELU()\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): SiLU()\n",
       "    (5): Linear(in_features=64, out_features=6, bias=True)\n",
       "  )\n",
       "  (state_mlp): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=64, bias=True)\n",
       "    (1): GELU()\n",
       "    (2): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (3): GELU()\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): GELU()\n",
       "    (6): Linear(in_features=64, out_features=3, bias=True)\n",
       "  )\n",
       "  (res_mlp): Sequential(\n",
       "    (0): Linear(in_features=6, out_features=64, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=64, out_features=3, bias=True)\n",
       "  )\n",
       "  (final_mlp): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=64, bias=True)\n",
       "    (1): GELU()\n",
       "    (2): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (3): GELU()\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): GELU()\n",
       "    (6): Linear(in_features=64, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = ErrorNet(dim=3)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c20362f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/tmp/adv_ml/diffusion_models/mountaincar/joint/thousand_steps.pth'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc1af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_size = batch.shape[0]\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        # Algorithm 1 line 3: sample t uniformally for every example in the batch\n",
    "        t = torch.randint(0, timesteps, (batch_size,), device=device).long()\n",
    "\n",
    "        loss = diffusion.p_losses(model, batch, t, loss_type=\"huber\")\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(\"Epoch: %d, Loss: %f\" %(epoch, loss.item()))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "path = '/tmp/adv_ml/diffusion_models/mountaincar/joint/thousand_steps.pth'\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0a67c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d482662",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for timestep in reversed(range(timesteps)):\n",
    "    diffusion.p_sample(model, x, timestep, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e4d9fe8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "[[-0.5372814  0.       ]]\n",
      "[[-0.5365116   0.00076979]]\n",
      "[[-0.5353332   0.00117837]]\n",
      "[[-0.53403455  0.00129864]]\n",
      "[[-0.5327331   0.00130148]]\n",
      "[[-0.53124607  0.00148699]]\n",
      "[[-0.52945113  0.00179494]]\n",
      "[[-0.5273889   0.00206225]]\n",
      "[[-0.52486205  0.00252679]]\n",
      "[[-0.5222018  0.0026603]]\n",
      "[[-0.5192413   0.00296053]]\n",
      "[[-0.5158618   0.00337946]]\n",
      "[[-0.5129677   0.00289411]]\n",
      "[[-0.50957793  0.00338978]]\n",
      "[[-0.5062923   0.00328564]]\n",
      "[[-0.5033015   0.00299081]]\n",
      "[[-0.49994075  0.00336075]]\n",
      "[[-0.4971649   0.00277585]]\n",
      "[[-0.49463698  0.00252792]]\n",
      "[[-0.49232212  0.00231488]]\n",
      "[[-0.48970488  0.00261725]]\n",
      "[[-0.4871277   0.00257719]]\n",
      "[[-0.48489556  0.00223214]]\n",
      "[[-0.48213553  0.00276003]]\n",
      "[[-0.47929072  0.00284481]]\n",
      "[[-0.47652882  0.00276189]]\n",
      "[[-0.4735205   0.00300834]]\n",
      "[[-0.47019964  0.00332085]]\n",
      "[[-0.46699584  0.0032038 ]]\n",
      "[[-0.46452177  0.00247406]]\n",
      "[[-0.46181217  0.00270961]]\n",
      "[[-0.45985064  0.00196154]]\n",
      "[[-0.4577859   0.00206472]]\n",
      "[[-0.4562404   0.00154552]]\n",
      "[[-0.45536652  0.00087387]]\n",
      "[[-4.5557454e-01 -2.0802538e-04]]\n",
      "[[-0.45622715 -0.00065261]]\n",
      "[[-0.456756   -0.00052885]]\n",
      "[[-0.45774528 -0.00098928]]\n",
      "[[-0.45863125 -0.00088595]]\n",
      "[[-0.45953056 -0.00089932]]\n",
      "[[-0.46093372 -0.00140316]]\n",
      "[[-0.46288717 -0.00195344]]\n",
      "[[-0.46510977 -0.0022226 ]]\n",
      "[[-0.4679352  -0.00282543]]\n",
      "[[-0.47097117 -0.00303597]]\n",
      "[[-0.4740866  -0.00311544]]\n",
      "[[-0.477814   -0.00372739]]\n",
      "[[-0.48236236 -0.00454836]]\n",
      "[[-0.4871872  -0.00482484]]\n",
      "[[-0.49283212 -0.00564491]]\n",
      "[[-0.49819303 -0.00536089]]\n",
      "[[-0.50329006 -0.00509704]]\n",
      "[[-0.50773764 -0.00444757]]\n",
      "[[-0.5120236 -0.004286 ]]\n",
      "[[-0.51612735 -0.00410375]]\n",
      "[[-0.519805   -0.00367768]]\n",
      "[[-0.5229162  -0.00311117]]\n",
      "[[-0.52600515 -0.00308893]]\n",
      "[[-0.5291065  -0.00310132]]\n",
      "[[-0.5321664  -0.00305995]]\n",
      "[[-0.5346939  -0.00252746]]\n",
      "[[-0.5366438  -0.00194989]]\n",
      "[[-0.5378906  -0.00124682]]\n",
      "[[-0.53894883 -0.0010582 ]]\n",
      "[[-5.3936374e-01 -4.1489469e-04]]\n",
      "[[-0.54017764 -0.00081391]]\n",
      "[[-5.4022384e-01 -4.6208643e-05]]\n",
      "[[-5.3972679e-01  4.9706106e-04]]\n",
      "[[-0.5383816  0.0013452]]\n",
      "[[-0.5371564   0.00122519]]\n",
      "[[-0.5357004   0.00145605]]\n",
      "[[-0.5340598   0.00164058]]\n",
      "[[-0.532197    0.00186281]]\n",
      "[[-0.5302526   0.00194442]]\n",
      "[[-0.5284675  0.0017851]]\n",
      "[[-0.52671725  0.00175025]]\n",
      "[[-0.5249562   0.00176101]]\n",
      "[[-0.52279174  0.0021645 ]]\n",
      "[[-0.5201756   0.00261614]]\n",
      "[[-0.5167665   0.00340908]]\n",
      "[[-0.513017    0.00374946]]\n",
      "[[-0.5095395   0.00347752]]\n",
      "[[-0.5062547   0.00328482]]\n",
      "[[-0.50258934  0.00366535]]\n",
      "[[-0.49905127  0.00353806]]\n",
      "[[-0.49558386  0.00346742]]\n",
      "[[-0.491588    0.00399587]]\n",
      "[[-0.48779368  0.00379432]]\n",
      "[[-0.48396793  0.00382574]]\n",
      "[[-0.47957072  0.00439723]]\n",
      "[[-0.47489086  0.00467987]]\n",
      "[[-0.470716    0.00417486]]\n",
      "[[-0.46623793  0.00447807]]\n",
      "[[-0.4619252   0.00431273]]\n",
      "[[-0.4584882   0.00343702]]\n",
      "[[-0.45492116  0.00356705]]\n",
      "[[-0.45157403  0.00334711]]\n",
      "[[-0.44799587  0.00357815]]\n",
      "[[-0.44543627  0.00255961]]\n",
      "[[-0.4425315   0.00290477]]\n",
      "[[-0.43956122  0.00297028]]\n",
      "[[-0.436573    0.00298821]]\n",
      "[[-0.43343312  0.00313987]]\n",
      "[[-0.43038204  0.00305108]]\n",
      "[[-0.42858073  0.00180132]]\n",
      "[[-0.42716438  0.00141635]]\n",
      "[[-0.426111    0.00105335]]\n",
      "[[-0.4255588  0.0005522]]\n",
      "[[-4.253634e-01  1.954078e-04]]\n",
      "[[-4.2546964e-01 -1.0626015e-04]]\n",
      "[[-0.42595294 -0.0004833 ]]\n",
      "[[-0.42723024 -0.0012773 ]]\n",
      "[[-0.42933172 -0.00210149]]\n",
      "[[-0.43226475 -0.00293304]]\n",
      "[[-0.436408   -0.00414327]]\n",
      "[[-0.4408654  -0.00445739]]\n",
      "[[-0.44591996 -0.00505457]]\n",
      "[[-0.451597   -0.00567705]]\n",
      "[[-0.45858914 -0.00699212]]\n",
      "[[-0.46620315 -0.00761401]]\n",
      "[[-0.47453728 -0.00833412]]\n",
      "[[-0.483199   -0.00866173]]\n",
      "[[-0.4923266 -0.0091276]]\n",
      "[[-0.50204134 -0.00971478]]\n",
      "[[-0.5116052  -0.00956383]]\n",
      "[[-0.52180344 -0.01019825]]\n",
      "[[-0.5319568  -0.01015334]]\n",
      "[[-0.54230034 -0.01034356]]\n",
      "[[-0.5522935  -0.00999313]]\n",
      "[[-0.5623792  -0.01008568]]\n",
      "[[-0.5719181 -0.0095389]]\n",
      "[[-0.5808354  -0.00891735]]\n",
      "[[-0.5891749  -0.00833955]]\n",
      "[[-0.59718174 -0.00800679]]\n",
      "[[-0.60446674 -0.007285  ]]\n",
      "[[-0.6112353  -0.00676858]]\n",
      "[[-0.6171461  -0.00591073]]\n",
      "[[-0.62186766 -0.00472161]]\n",
      "[[-0.62590104 -0.00403336]]\n",
      "[[-0.6294908  -0.00358977]]\n",
      "[[-0.6319931  -0.00250233]]\n",
      "[[-0.633303   -0.00130988]]\n",
      "[[-6.3387001e-01 -5.6700734e-04]]\n",
      "[[-6.3362861e-01  2.4138927e-04]]\n",
      "[[-0.6325941   0.00103447]]\n",
      "[[-0.63096637  0.00162774]]\n",
      "[[-0.62809885  0.00286754]]\n",
      "[[-0.6239746   0.00412424]]\n",
      "[[-0.61827785  0.00569677]]\n",
      "[[-0.6110443   0.00723357]]\n",
      "[[-0.6022797   0.00876459]]\n",
      "[[-0.5919567   0.01032303]]\n",
      "[[-0.5801602  0.0117965]]\n",
      "[[-0.56755733  0.01260287]]\n",
      "[[-0.5545621   0.01299523]]\n",
      "[[-0.540965    0.01359707]]\n",
      "[[-0.52603275  0.0149323 ]]\n",
      "[[-0.5102215   0.01581125]]\n",
      "[[-0.49382174  0.01639974]]\n",
      "[[-0.47678125  0.0170405 ]]\n",
      "[[-0.45901695  0.0177643 ]]\n",
      "[[-0.44074562  0.01827133]]\n",
      "[[-0.42253846  0.01820716]]\n",
      "[[-0.40388018  0.01865829]]\n",
      "[[-0.38565964  0.01822056]]\n",
      "[[-0.36717376  0.01848587]]\n",
      "[[-0.34969285  0.01748091]]\n",
      "[[-0.33235243  0.01734042]]\n",
      "[[-0.315196    0.01715644]]\n",
      "[[-0.2994722   0.01572381]]\n",
      "[[-0.2850062   0.01446601]]\n",
      "[[-0.2710849  0.0139213]]\n",
      "[[-0.2578608  0.0132241]]\n",
      "[[-0.24593066  0.01193015]]\n",
      "[[-0.23483118  0.01109948]]\n",
      "[[-0.22545423  0.00937696]]\n",
      "[[-0.2171052   0.00834903]]\n",
      "[[-0.20970735  0.00739785]]\n",
      "[[-0.20410515  0.0056022 ]]\n",
      "[[-0.20011169  0.00399347]]\n",
      "[[-0.19837353  0.00173817]]\n",
      "[[-0.1979623   0.00041122]]\n",
      "[[-0.19960554 -0.00164324]]\n",
      "[[-0.20317969 -0.00357415]]\n",
      "[[-0.2082774  -0.00509771]]\n",
      "[[-0.21561565 -0.00733824]]\n",
      "[[-0.22505344 -0.00943779]]\n",
      "[[-0.23647442 -0.01142097]]\n",
      "[[-0.24963231 -0.01315789]]\n",
      "[[-0.2641975  -0.01456518]]\n",
      "[[-0.28018442 -0.0159869 ]]\n",
      "[[-0.29879746 -0.01861304]]\n",
      "[[-0.3197646  -0.02096714]]\n",
      "[[-0.34284672 -0.02308212]]\n",
      "[[-0.3682267  -0.02537999]]\n",
      "[[-0.39531222 -0.02708552]]\n",
      "[[-0.42432448 -0.02901227]]\n",
      "[[-0.45476598 -0.03044149]]\n",
      "[[-0.48662582 -0.03185985]]\n",
      "[[-0.5193391  -0.03271327]]\n",
      "[[-0.5523515  -0.03301239]]\n",
      "[[-0.5859244  -0.03357294]]\n",
      "[[-0.6195717  -0.03364732]]\n",
      "[[-0.65322685 -0.03365518]]\n",
      "[[-0.68659383 -0.03336696]]\n",
      "[[-0.719383   -0.03278917]]\n",
      "[[-0.7511683  -0.03178531]]\n",
      "[[-0.7818249  -0.03065656]]\n",
      "[[-0.81101465 -0.02918976]]\n",
      "[[-0.83836997 -0.02735529]]\n",
      "[[-0.8640237  -0.02565371]]\n",
      "[[-0.88729125 -0.02326754]]\n",
      "[[-0.90820545 -0.02091417]]\n",
      "[[-0.92678815 -0.01858269]]\n",
      "[[-0.94263124 -0.01584307]]\n",
      "[[-0.9555726  -0.01294133]]\n",
      "[[-0.9659236 -0.010351 ]]\n",
      "[[-0.9736614  -0.00773784]]\n",
      "[[-0.9787775  -0.00511613]]\n",
      "[[-0.9809044  -0.00212687]]\n",
      "[[-9.7995347e-01  9.5091172e-04]]\n",
      "[[-0.9757975   0.00415602]]\n",
      "[[-0.9685208   0.00727667]]\n",
      "[[-0.958506    0.01001484]]\n",
      "[[-0.9453161   0.01318993]]\n",
      "[[-0.9287816   0.01653447]]\n",
      "[[-0.908732    0.02004965]]\n",
      "[[-0.88506466  0.02366734]]\n",
      "[[-0.85853255  0.02653209]]\n",
      "[[-0.82859164  0.02994091]]\n",
      "[[-0.7953138   0.03327786]]\n",
      "[[-0.75898635  0.0363274 ]]\n",
      "[[-0.7195523   0.03943407]]\n",
      "[[-0.6776719   0.04188035]]\n",
      "[[-0.6335254   0.04414653]]\n",
      "[[-0.58730525  0.04622011]]\n",
      "[[-0.5394378   0.04786751]]\n",
      "[[-0.49020997  0.04922782]]\n",
      "[[-0.4397816   0.05042835]]\n",
      "[[-0.3884753   0.05130632]]\n",
      "[[-0.33665922  0.05181609]]\n",
      "[[-0.28469628  0.05196293]]\n",
      "[[-0.23289435  0.05180194]]\n",
      "[[-0.18150663  0.05138771]]\n",
      "[[-0.13076733  0.05073931]]\n",
      "[[-0.08088596  0.04988137]]\n",
      "[[-0.03193135  0.04895461]]\n",
      "[[0.01494265 0.04687399]]\n",
      "[[0.0607596  0.04581696]]\n",
      "[[0.10561798 0.04485837]]\n",
      "[[0.1496008  0.04398282]]\n",
      "[[0.19282077 0.04321996]]\n",
      "[[0.23544748 0.04262671]]\n",
      "[[0.27766514 0.04221764]]\n",
      "[[0.3193922  0.04172707]]\n",
      "[[0.36113483 0.04174262]]\n",
      "[[0.40320665 0.04207181]]\n",
      "[[0.44589502 0.04268837]]\n",
      "reward at the end of the episode :  [99.89967]\n"
     ]
    }
   ],
   "source": [
    "mask = torch.tensor([[1.0, 1.0, 0.0]], device=device)\n",
    "a = torch.randn(1,1).to(device)\n",
    "a = torch.clamp(a, -1, 1)\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    obs = env.reset()\n",
    "    print(obs.shape)\n",
    "    done = False \n",
    "    while not done:\n",
    "        print(obs)\n",
    "        # inpainting\n",
    "        cond = torch.tensor((obs-bias)/scale).to(device)\n",
    "        x = torch.cat((cond,a),-1)\n",
    "        g = torch.randn(x.shape, device=device)\n",
    "        for i in reversed(range(0, timesteps)):\n",
    "            t = torch.tensor([i], device=device)\n",
    "            x_noisy = diffusion.q_sample(x, t)\n",
    "            g = diffusion.p_sample(model, g, t, i)\n",
    "            g = x_noisy * mask + g * (1 - mask)\n",
    "        \n",
    "        g = g.cpu().numpy()\n",
    "        action = [[g[0][-1]]]\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"reward at the end of the episode : \", reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9513f297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2395,  0.0125,  0.3885]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "obs = env.reset()\n",
    "cond = torch.tensor((obs-bias)/scale).to(device)\n",
    "\n",
    "x = torch.cat((cond,a),-1)\n",
    "g = torch.randn(x.shape, device=device)\n",
    "for i in reversed(range(0, timesteps)):\n",
    "    t = torch.tensor([i], device=device)\n",
    "    x_noisy = diffusion.q_sample(x, t)\n",
    "    g = diffusion.p_sample(model, g, t, i)\n",
    "    g = x_noisy * mask + g * (1 - mask)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "12d14f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_noisy = diffusion.q_sample(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "59ad8a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38854772]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = g.cpu().numpy()\n",
    "np.array([[g[0][-1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "33e22ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2377,  0.0009,  0.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_noisy * (mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5c1e970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e-04, 1.1992e-04, 1.3984e-04, 1.5976e-04, 1.7968e-04, 1.9960e-04,\n",
       "        2.1952e-04, 2.3944e-04, 2.5936e-04, 2.7928e-04, 2.9920e-04, 3.1912e-04,\n",
       "        3.3904e-04, 3.5896e-04, 3.7888e-04, 3.9880e-04, 4.1872e-04, 4.3864e-04,\n",
       "        4.5856e-04, 4.7848e-04, 4.9840e-04, 5.1832e-04, 5.3824e-04, 5.5816e-04,\n",
       "        5.7808e-04, 5.9800e-04, 6.1792e-04, 6.3784e-04, 6.5776e-04, 6.7768e-04,\n",
       "        6.9760e-04, 7.1752e-04, 7.3744e-04, 7.5736e-04, 7.7728e-04, 7.9720e-04,\n",
       "        8.1712e-04, 8.3704e-04, 8.5696e-04, 8.7688e-04, 8.9680e-04, 9.1672e-04,\n",
       "        9.3664e-04, 9.5656e-04, 9.7648e-04, 9.9640e-04, 1.0163e-03, 1.0362e-03,\n",
       "        1.0562e-03, 1.0761e-03, 1.0960e-03, 1.1159e-03, 1.1358e-03, 1.1558e-03,\n",
       "        1.1757e-03, 1.1956e-03, 1.2155e-03, 1.2354e-03, 1.2554e-03, 1.2753e-03,\n",
       "        1.2952e-03, 1.3151e-03, 1.3350e-03, 1.3550e-03, 1.3749e-03, 1.3948e-03,\n",
       "        1.4147e-03, 1.4346e-03, 1.4546e-03, 1.4745e-03, 1.4944e-03, 1.5143e-03,\n",
       "        1.5342e-03, 1.5542e-03, 1.5741e-03, 1.5940e-03, 1.6139e-03, 1.6338e-03,\n",
       "        1.6538e-03, 1.6737e-03, 1.6936e-03, 1.7135e-03, 1.7334e-03, 1.7534e-03,\n",
       "        1.7733e-03, 1.7932e-03, 1.8131e-03, 1.8330e-03, 1.8530e-03, 1.8729e-03,\n",
       "        1.8928e-03, 1.9127e-03, 1.9326e-03, 1.9526e-03, 1.9725e-03, 1.9924e-03,\n",
       "        2.0123e-03, 2.0322e-03, 2.0522e-03, 2.0721e-03, 2.0920e-03, 2.1119e-03,\n",
       "        2.1318e-03, 2.1518e-03, 2.1717e-03, 2.1916e-03, 2.2115e-03, 2.2314e-03,\n",
       "        2.2514e-03, 2.2713e-03, 2.2912e-03, 2.3111e-03, 2.3310e-03, 2.3510e-03,\n",
       "        2.3709e-03, 2.3908e-03, 2.4107e-03, 2.4306e-03, 2.4506e-03, 2.4705e-03,\n",
       "        2.4904e-03, 2.5103e-03, 2.5302e-03, 2.5502e-03, 2.5701e-03, 2.5900e-03,\n",
       "        2.6099e-03, 2.6298e-03, 2.6497e-03, 2.6697e-03, 2.6896e-03, 2.7095e-03,\n",
       "        2.7294e-03, 2.7493e-03, 2.7693e-03, 2.7892e-03, 2.8091e-03, 2.8290e-03,\n",
       "        2.8489e-03, 2.8689e-03, 2.8888e-03, 2.9087e-03, 2.9286e-03, 2.9485e-03,\n",
       "        2.9685e-03, 2.9884e-03, 3.0083e-03, 3.0282e-03, 3.0481e-03, 3.0681e-03,\n",
       "        3.0880e-03, 3.1079e-03, 3.1278e-03, 3.1477e-03, 3.1677e-03, 3.1876e-03,\n",
       "        3.2075e-03, 3.2274e-03, 3.2473e-03, 3.2673e-03, 3.2872e-03, 3.3071e-03,\n",
       "        3.3270e-03, 3.3469e-03, 3.3669e-03, 3.3868e-03, 3.4067e-03, 3.4266e-03,\n",
       "        3.4465e-03, 3.4665e-03, 3.4864e-03, 3.5063e-03, 3.5262e-03, 3.5461e-03,\n",
       "        3.5661e-03, 3.5860e-03, 3.6059e-03, 3.6258e-03, 3.6457e-03, 3.6657e-03,\n",
       "        3.6856e-03, 3.7055e-03, 3.7254e-03, 3.7453e-03, 3.7653e-03, 3.7852e-03,\n",
       "        3.8051e-03, 3.8250e-03, 3.8449e-03, 3.8649e-03, 3.8848e-03, 3.9047e-03,\n",
       "        3.9246e-03, 3.9445e-03, 3.9645e-03, 3.9844e-03, 4.0043e-03, 4.0242e-03,\n",
       "        4.0441e-03, 4.0641e-03, 4.0840e-03, 4.1039e-03, 4.1238e-03, 4.1437e-03,\n",
       "        4.1637e-03, 4.1836e-03, 4.2035e-03, 4.2234e-03, 4.2433e-03, 4.2633e-03,\n",
       "        4.2832e-03, 4.3031e-03, 4.3230e-03, 4.3429e-03, 4.3629e-03, 4.3828e-03,\n",
       "        4.4027e-03, 4.4226e-03, 4.4425e-03, 4.4625e-03, 4.4824e-03, 4.5023e-03,\n",
       "        4.5222e-03, 4.5421e-03, 4.5621e-03, 4.5820e-03, 4.6019e-03, 4.6218e-03,\n",
       "        4.6417e-03, 4.6617e-03, 4.6816e-03, 4.7015e-03, 4.7214e-03, 4.7413e-03,\n",
       "        4.7613e-03, 4.7812e-03, 4.8011e-03, 4.8210e-03, 4.8409e-03, 4.8609e-03,\n",
       "        4.8808e-03, 4.9007e-03, 4.9206e-03, 4.9405e-03, 4.9605e-03, 4.9804e-03,\n",
       "        5.0003e-03, 5.0202e-03, 5.0401e-03, 5.0601e-03, 5.0800e-03, 5.0999e-03,\n",
       "        5.1198e-03, 5.1397e-03, 5.1597e-03, 5.1796e-03, 5.1995e-03, 5.2194e-03,\n",
       "        5.2393e-03, 5.2593e-03, 5.2792e-03, 5.2991e-03, 5.3190e-03, 5.3389e-03,\n",
       "        5.3589e-03, 5.3788e-03, 5.3987e-03, 5.4186e-03, 5.4385e-03, 5.4585e-03,\n",
       "        5.4784e-03, 5.4983e-03, 5.5182e-03, 5.5381e-03, 5.5581e-03, 5.5780e-03,\n",
       "        5.5979e-03, 5.6178e-03, 5.6377e-03, 5.6577e-03, 5.6776e-03, 5.6975e-03,\n",
       "        5.7174e-03, 5.7373e-03, 5.7573e-03, 5.7772e-03, 5.7971e-03, 5.8170e-03,\n",
       "        5.8369e-03, 5.8569e-03, 5.8768e-03, 5.8967e-03, 5.9166e-03, 5.9365e-03,\n",
       "        5.9565e-03, 5.9764e-03, 5.9963e-03, 6.0162e-03, 6.0361e-03, 6.0561e-03,\n",
       "        6.0760e-03, 6.0959e-03, 6.1158e-03, 6.1357e-03, 6.1557e-03, 6.1756e-03,\n",
       "        6.1955e-03, 6.2154e-03, 6.2353e-03, 6.2553e-03, 6.2752e-03, 6.2951e-03,\n",
       "        6.3150e-03, 6.3349e-03, 6.3549e-03, 6.3748e-03, 6.3947e-03, 6.4146e-03,\n",
       "        6.4345e-03, 6.4545e-03, 6.4744e-03, 6.4943e-03, 6.5142e-03, 6.5341e-03,\n",
       "        6.5541e-03, 6.5740e-03, 6.5939e-03, 6.6138e-03, 6.6337e-03, 6.6537e-03,\n",
       "        6.6736e-03, 6.6935e-03, 6.7134e-03, 6.7333e-03, 6.7533e-03, 6.7732e-03,\n",
       "        6.7931e-03, 6.8130e-03, 6.8329e-03, 6.8529e-03, 6.8728e-03, 6.8927e-03,\n",
       "        6.9126e-03, 6.9325e-03, 6.9525e-03, 6.9724e-03, 6.9923e-03, 7.0122e-03,\n",
       "        7.0321e-03, 7.0521e-03, 7.0720e-03, 7.0919e-03, 7.1118e-03, 7.1317e-03,\n",
       "        7.1517e-03, 7.1716e-03, 7.1915e-03, 7.2114e-03, 7.2313e-03, 7.2513e-03,\n",
       "        7.2712e-03, 7.2911e-03, 7.3110e-03, 7.3309e-03, 7.3509e-03, 7.3708e-03,\n",
       "        7.3907e-03, 7.4106e-03, 7.4305e-03, 7.4505e-03, 7.4704e-03, 7.4903e-03,\n",
       "        7.5102e-03, 7.5301e-03, 7.5501e-03, 7.5700e-03, 7.5899e-03, 7.6098e-03,\n",
       "        7.6297e-03, 7.6496e-03, 7.6696e-03, 7.6895e-03, 7.7094e-03, 7.7293e-03,\n",
       "        7.7492e-03, 7.7692e-03, 7.7891e-03, 7.8090e-03, 7.8289e-03, 7.8488e-03,\n",
       "        7.8688e-03, 7.8887e-03, 7.9086e-03, 7.9285e-03, 7.9484e-03, 7.9684e-03,\n",
       "        7.9883e-03, 8.0082e-03, 8.0281e-03, 8.0480e-03, 8.0680e-03, 8.0879e-03,\n",
       "        8.1078e-03, 8.1277e-03, 8.1476e-03, 8.1676e-03, 8.1875e-03, 8.2074e-03,\n",
       "        8.2273e-03, 8.2472e-03, 8.2672e-03, 8.2871e-03, 8.3070e-03, 8.3269e-03,\n",
       "        8.3468e-03, 8.3668e-03, 8.3867e-03, 8.4066e-03, 8.4265e-03, 8.4464e-03,\n",
       "        8.4664e-03, 8.4863e-03, 8.5062e-03, 8.5261e-03, 8.5460e-03, 8.5660e-03,\n",
       "        8.5859e-03, 8.6058e-03, 8.6257e-03, 8.6456e-03, 8.6656e-03, 8.6855e-03,\n",
       "        8.7054e-03, 8.7253e-03, 8.7452e-03, 8.7652e-03, 8.7851e-03, 8.8050e-03,\n",
       "        8.8249e-03, 8.8448e-03, 8.8648e-03, 8.8847e-03, 8.9046e-03, 8.9245e-03,\n",
       "        8.9444e-03, 8.9644e-03, 8.9843e-03, 9.0042e-03, 9.0241e-03, 9.0440e-03,\n",
       "        9.0640e-03, 9.0839e-03, 9.1038e-03, 9.1237e-03, 9.1436e-03, 9.1636e-03,\n",
       "        9.1835e-03, 9.2034e-03, 9.2233e-03, 9.2432e-03, 9.2632e-03, 9.2831e-03,\n",
       "        9.3030e-03, 9.3229e-03, 9.3428e-03, 9.3628e-03, 9.3827e-03, 9.4026e-03,\n",
       "        9.4225e-03, 9.4424e-03, 9.4624e-03, 9.4823e-03, 9.5022e-03, 9.5221e-03,\n",
       "        9.5420e-03, 9.5620e-03, 9.5819e-03, 9.6018e-03, 9.6217e-03, 9.6416e-03,\n",
       "        9.6616e-03, 9.6815e-03, 9.7014e-03, 9.7213e-03, 9.7412e-03, 9.7612e-03,\n",
       "        9.7811e-03, 9.8010e-03, 9.8209e-03, 9.8408e-03, 9.8608e-03, 9.8807e-03,\n",
       "        9.9006e-03, 9.9205e-03, 9.9404e-03, 9.9604e-03, 9.9803e-03, 1.0000e-02,\n",
       "        1.0020e-02, 1.0040e-02, 1.0060e-02, 1.0080e-02, 1.0100e-02, 1.0120e-02,\n",
       "        1.0140e-02, 1.0160e-02, 1.0179e-02, 1.0199e-02, 1.0219e-02, 1.0239e-02,\n",
       "        1.0259e-02, 1.0279e-02, 1.0299e-02, 1.0319e-02, 1.0339e-02, 1.0359e-02,\n",
       "        1.0379e-02, 1.0399e-02, 1.0419e-02, 1.0438e-02, 1.0458e-02, 1.0478e-02,\n",
       "        1.0498e-02, 1.0518e-02, 1.0538e-02, 1.0558e-02, 1.0578e-02, 1.0598e-02,\n",
       "        1.0618e-02, 1.0638e-02, 1.0658e-02, 1.0677e-02, 1.0697e-02, 1.0717e-02,\n",
       "        1.0737e-02, 1.0757e-02, 1.0777e-02, 1.0797e-02, 1.0817e-02, 1.0837e-02,\n",
       "        1.0857e-02, 1.0877e-02, 1.0897e-02, 1.0917e-02, 1.0936e-02, 1.0956e-02,\n",
       "        1.0976e-02, 1.0996e-02, 1.1016e-02, 1.1036e-02, 1.1056e-02, 1.1076e-02,\n",
       "        1.1096e-02, 1.1116e-02, 1.1136e-02, 1.1156e-02, 1.1175e-02, 1.1195e-02,\n",
       "        1.1215e-02, 1.1235e-02, 1.1255e-02, 1.1275e-02, 1.1295e-02, 1.1315e-02,\n",
       "        1.1335e-02, 1.1355e-02, 1.1375e-02, 1.1395e-02, 1.1415e-02, 1.1434e-02,\n",
       "        1.1454e-02, 1.1474e-02, 1.1494e-02, 1.1514e-02, 1.1534e-02, 1.1554e-02,\n",
       "        1.1574e-02, 1.1594e-02, 1.1614e-02, 1.1634e-02, 1.1654e-02, 1.1673e-02,\n",
       "        1.1693e-02, 1.1713e-02, 1.1733e-02, 1.1753e-02, 1.1773e-02, 1.1793e-02,\n",
       "        1.1813e-02, 1.1833e-02, 1.1853e-02, 1.1873e-02, 1.1893e-02, 1.1913e-02,\n",
       "        1.1932e-02, 1.1952e-02, 1.1972e-02, 1.1992e-02, 1.2012e-02, 1.2032e-02,\n",
       "        1.2052e-02, 1.2072e-02, 1.2092e-02, 1.2112e-02, 1.2132e-02, 1.2152e-02,\n",
       "        1.2171e-02, 1.2191e-02, 1.2211e-02, 1.2231e-02, 1.2251e-02, 1.2271e-02,\n",
       "        1.2291e-02, 1.2311e-02, 1.2331e-02, 1.2351e-02, 1.2371e-02, 1.2391e-02,\n",
       "        1.2411e-02, 1.2430e-02, 1.2450e-02, 1.2470e-02, 1.2490e-02, 1.2510e-02,\n",
       "        1.2530e-02, 1.2550e-02, 1.2570e-02, 1.2590e-02, 1.2610e-02, 1.2630e-02,\n",
       "        1.2650e-02, 1.2669e-02, 1.2689e-02, 1.2709e-02, 1.2729e-02, 1.2749e-02,\n",
       "        1.2769e-02, 1.2789e-02, 1.2809e-02, 1.2829e-02, 1.2849e-02, 1.2869e-02,\n",
       "        1.2889e-02, 1.2909e-02, 1.2928e-02, 1.2948e-02, 1.2968e-02, 1.2988e-02,\n",
       "        1.3008e-02, 1.3028e-02, 1.3048e-02, 1.3068e-02, 1.3088e-02, 1.3108e-02,\n",
       "        1.3128e-02, 1.3148e-02, 1.3167e-02, 1.3187e-02, 1.3207e-02, 1.3227e-02,\n",
       "        1.3247e-02, 1.3267e-02, 1.3287e-02, 1.3307e-02, 1.3327e-02, 1.3347e-02,\n",
       "        1.3367e-02, 1.3387e-02, 1.3407e-02, 1.3426e-02, 1.3446e-02, 1.3466e-02,\n",
       "        1.3486e-02, 1.3506e-02, 1.3526e-02, 1.3546e-02, 1.3566e-02, 1.3586e-02,\n",
       "        1.3606e-02, 1.3626e-02, 1.3646e-02, 1.3665e-02, 1.3685e-02, 1.3705e-02,\n",
       "        1.3725e-02, 1.3745e-02, 1.3765e-02, 1.3785e-02, 1.3805e-02, 1.3825e-02,\n",
       "        1.3845e-02, 1.3865e-02, 1.3885e-02, 1.3905e-02, 1.3924e-02, 1.3944e-02,\n",
       "        1.3964e-02, 1.3984e-02, 1.4004e-02, 1.4024e-02, 1.4044e-02, 1.4064e-02,\n",
       "        1.4084e-02, 1.4104e-02, 1.4124e-02, 1.4144e-02, 1.4163e-02, 1.4183e-02,\n",
       "        1.4203e-02, 1.4223e-02, 1.4243e-02, 1.4263e-02, 1.4283e-02, 1.4303e-02,\n",
       "        1.4323e-02, 1.4343e-02, 1.4363e-02, 1.4383e-02, 1.4403e-02, 1.4422e-02,\n",
       "        1.4442e-02, 1.4462e-02, 1.4482e-02, 1.4502e-02, 1.4522e-02, 1.4542e-02,\n",
       "        1.4562e-02, 1.4582e-02, 1.4602e-02, 1.4622e-02, 1.4642e-02, 1.4661e-02,\n",
       "        1.4681e-02, 1.4701e-02, 1.4721e-02, 1.4741e-02, 1.4761e-02, 1.4781e-02,\n",
       "        1.4801e-02, 1.4821e-02, 1.4841e-02, 1.4861e-02, 1.4881e-02, 1.4900e-02,\n",
       "        1.4920e-02, 1.4940e-02, 1.4960e-02, 1.4980e-02, 1.5000e-02, 1.5020e-02,\n",
       "        1.5040e-02, 1.5060e-02, 1.5080e-02, 1.5100e-02, 1.5120e-02, 1.5140e-02,\n",
       "        1.5159e-02, 1.5179e-02, 1.5199e-02, 1.5219e-02, 1.5239e-02, 1.5259e-02,\n",
       "        1.5279e-02, 1.5299e-02, 1.5319e-02, 1.5339e-02, 1.5359e-02, 1.5379e-02,\n",
       "        1.5398e-02, 1.5418e-02, 1.5438e-02, 1.5458e-02, 1.5478e-02, 1.5498e-02,\n",
       "        1.5518e-02, 1.5538e-02, 1.5558e-02, 1.5578e-02, 1.5598e-02, 1.5618e-02,\n",
       "        1.5638e-02, 1.5657e-02, 1.5677e-02, 1.5697e-02, 1.5717e-02, 1.5737e-02,\n",
       "        1.5757e-02, 1.5777e-02, 1.5797e-02, 1.5817e-02, 1.5837e-02, 1.5857e-02,\n",
       "        1.5877e-02, 1.5896e-02, 1.5916e-02, 1.5936e-02, 1.5956e-02, 1.5976e-02,\n",
       "        1.5996e-02, 1.6016e-02, 1.6036e-02, 1.6056e-02, 1.6076e-02, 1.6096e-02,\n",
       "        1.6116e-02, 1.6136e-02, 1.6155e-02, 1.6175e-02, 1.6195e-02, 1.6215e-02,\n",
       "        1.6235e-02, 1.6255e-02, 1.6275e-02, 1.6295e-02, 1.6315e-02, 1.6335e-02,\n",
       "        1.6355e-02, 1.6375e-02, 1.6394e-02, 1.6414e-02, 1.6434e-02, 1.6454e-02,\n",
       "        1.6474e-02, 1.6494e-02, 1.6514e-02, 1.6534e-02, 1.6554e-02, 1.6574e-02,\n",
       "        1.6594e-02, 1.6614e-02, 1.6634e-02, 1.6653e-02, 1.6673e-02, 1.6693e-02,\n",
       "        1.6713e-02, 1.6733e-02, 1.6753e-02, 1.6773e-02, 1.6793e-02, 1.6813e-02,\n",
       "        1.6833e-02, 1.6853e-02, 1.6873e-02, 1.6892e-02, 1.6912e-02, 1.6932e-02,\n",
       "        1.6952e-02, 1.6972e-02, 1.6992e-02, 1.7012e-02, 1.7032e-02, 1.7052e-02,\n",
       "        1.7072e-02, 1.7092e-02, 1.7112e-02, 1.7132e-02, 1.7151e-02, 1.7171e-02,\n",
       "        1.7191e-02, 1.7211e-02, 1.7231e-02, 1.7251e-02, 1.7271e-02, 1.7291e-02,\n",
       "        1.7311e-02, 1.7331e-02, 1.7351e-02, 1.7371e-02, 1.7390e-02, 1.7410e-02,\n",
       "        1.7430e-02, 1.7450e-02, 1.7470e-02, 1.7490e-02, 1.7510e-02, 1.7530e-02,\n",
       "        1.7550e-02, 1.7570e-02, 1.7590e-02, 1.7610e-02, 1.7630e-02, 1.7649e-02,\n",
       "        1.7669e-02, 1.7689e-02, 1.7709e-02, 1.7729e-02, 1.7749e-02, 1.7769e-02,\n",
       "        1.7789e-02, 1.7809e-02, 1.7829e-02, 1.7849e-02, 1.7869e-02, 1.7888e-02,\n",
       "        1.7908e-02, 1.7928e-02, 1.7948e-02, 1.7968e-02, 1.7988e-02, 1.8008e-02,\n",
       "        1.8028e-02, 1.8048e-02, 1.8068e-02, 1.8088e-02, 1.8108e-02, 1.8128e-02,\n",
       "        1.8147e-02, 1.8167e-02, 1.8187e-02, 1.8207e-02, 1.8227e-02, 1.8247e-02,\n",
       "        1.8267e-02, 1.8287e-02, 1.8307e-02, 1.8327e-02, 1.8347e-02, 1.8367e-02,\n",
       "        1.8386e-02, 1.8406e-02, 1.8426e-02, 1.8446e-02, 1.8466e-02, 1.8486e-02,\n",
       "        1.8506e-02, 1.8526e-02, 1.8546e-02, 1.8566e-02, 1.8586e-02, 1.8606e-02,\n",
       "        1.8626e-02, 1.8645e-02, 1.8665e-02, 1.8685e-02, 1.8705e-02, 1.8725e-02,\n",
       "        1.8745e-02, 1.8765e-02, 1.8785e-02, 1.8805e-02, 1.8825e-02, 1.8845e-02,\n",
       "        1.8865e-02, 1.8884e-02, 1.8904e-02, 1.8924e-02, 1.8944e-02, 1.8964e-02,\n",
       "        1.8984e-02, 1.9004e-02, 1.9024e-02, 1.9044e-02, 1.9064e-02, 1.9084e-02,\n",
       "        1.9104e-02, 1.9124e-02, 1.9143e-02, 1.9163e-02, 1.9183e-02, 1.9203e-02,\n",
       "        1.9223e-02, 1.9243e-02, 1.9263e-02, 1.9283e-02, 1.9303e-02, 1.9323e-02,\n",
       "        1.9343e-02, 1.9363e-02, 1.9382e-02, 1.9402e-02, 1.9422e-02, 1.9442e-02,\n",
       "        1.9462e-02, 1.9482e-02, 1.9502e-02, 1.9522e-02, 1.9542e-02, 1.9562e-02,\n",
       "        1.9582e-02, 1.9602e-02, 1.9622e-02, 1.9641e-02, 1.9661e-02, 1.9681e-02,\n",
       "        1.9701e-02, 1.9721e-02, 1.9741e-02, 1.9761e-02, 1.9781e-02, 1.9801e-02,\n",
       "        1.9821e-02, 1.9841e-02, 1.9861e-02, 1.9880e-02, 1.9900e-02, 1.9920e-02,\n",
       "        1.9940e-02, 1.9960e-02, 1.9980e-02, 2.0000e-02])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57025bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
